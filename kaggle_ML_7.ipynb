{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle - Learn: Intro to Machine Learning\n",
    "- https://www.kaggle.com/learn/intro-to-machine-learning\n",
    "## 7. Machine Learning Competitions\n",
    "- Enter the world of machine learning competitions to keep improving and see your progress."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Machine Learning Competitions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Prices Competition for Kaggle Learn Users\n",
    "- In this exercise, you will create and submit predictions for a Kaggle competition. You can then improve your model (e.g. by adding features) to apply what you've learned and move up the leaderboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>2003</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>2001</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>1915</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>2000</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
       "0     8450       2003       856       854         2             3   \n",
       "1     9600       1976      1262         0         2             3   \n",
       "2    11250       2001       920       866         2             3   \n",
       "3     9550       1915       961       756         1             3   \n",
       "4    14260       2000      1145      1053         2             4   \n",
       "\n",
       "   TotRmsAbvGrd  \n",
       "0             8  \n",
       "1             6  \n",
       "2             6  \n",
       "3             7  \n",
       "4             9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_mae: 20,353.67\n",
      "rf_mae: 20,353.67\n",
      "\n",
      "Validation MAE for Random Forest model: 20,354\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from pprint import pprint\n",
    "\n",
    "# Load the data, and separate the target \n",
    "#home_data = pd.read_csv('train.csv', index_col=0)   # supposes not na values ¿?\n",
    "home_data = pd.read_csv('train.csv')   # supposes not na values ¿?\n",
    "y = home_data.SalePrice\n",
    "\n",
    "# Create X (separate features) - After completing the exercise, you can return to modify this line!\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]\n",
    "display(X.head())\n",
    "\n",
    "# Split into training and validation (test) data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=18)\n",
    "\n",
    "# Define Random Forest model + fit it with training data + mk val_predicted + calc mae\n",
    "rf_model = RandomForestRegressor(random_state=18)\n",
    "rf_model.fit(train_X, train_y)\n",
    "rf_val_predictions = rf_model.predict(val_X)\n",
    "rf_mae = mean_absolute_error(val_y, rf_val_predictions)\n",
    "print(f'rf_mae: {rf_mae:,.2f}')\n",
    "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
    "print(f'rf_mae: {rf_val_mae:,.2f}')\n",
    "print()\n",
    "print(f'Validation MAE for Random Forest model: {rf_val_mae:,.0f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state: 97  -->  rf_mae: 19,639.44\n"
     ]
    }
   ],
   "source": [
    "### this is JM trying to mk an improved model.\n",
    "## 2. modifying random state ¿? -- YESS selecting the same random_state in train_test_split and in de model definition\n",
    "def get_mae_randstate(randstate):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=randstate)\n",
    "    rf_m2 = RandomForestRegressor(random_state=randstate)\n",
    "    rf_m2.fit(train_X, train_y)\n",
    "    rf_pred2 = rf_m2.predict(val_X)\n",
    "    rf_mae2 = mean_absolute_error(val_y, rf_pred2)\n",
    "    return rf_mae2\n",
    "\n",
    "dic = {}\n",
    "for i in range(300):\n",
    "    rf_mae2 = get_mae_randstate(i)\n",
    "    dic[i] = rf_mae2\n",
    "\n",
    "min_mae = min(dic.values())\n",
    "for k in dic.keys():\n",
    "    if dic[k] == min_mae:\n",
    "        k_min = k\n",
    "        break\n",
    "\n",
    "print(f'random_state: {k_min}  -->  rf_mae: {min_mae:,.2f}')\n",
    "#print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_mae: 17,905.90\n"
     ]
    }
   ],
   "source": [
    "### this is JM trying to mk an improved model.\n",
    "## 3. all cols in features but not the ones that are erroneous\n",
    "    # Some features will cause errors because of issues like missing values or non-numeric data types.\n",
    "    # Look at the list of columns and think about what might affect home prices.\n",
    "    # To learn more about each of these features, take a look at the data description\n",
    "\n",
    "# Let's try first with ALL not-gen-error cols:\n",
    "''' Id,MSSubClass,MSZoning,LotFrontage,LotArea,Street,Alley,LotShape,LandContour,Utilities,LotConfig,LandSlope,\n",
    "Neighborhood,Condition1,Condition2,BldgType,HouseStyle,OverallQual,OverallCond,YearBuilt,YearRemodAdd,RoofStyle,\n",
    "RoofMatl,Exterior1st,Exterior2nd,MasVnrType,MasVnrArea,ExterQual,ExterCond,Foundation,BsmtQual,BsmtCond,\n",
    "BsmtExposure,BsmtFinType1,BsmtFinSF1,BsmtFinType2,BsmtFinSF2,BsmtUnfSF,TotalBsmtSF,Heating,HeatingQC,CentralAir,\n",
    "Electrical,1stFlrSF,2ndFlrSF,LowQualFinSF,GrLivArea,BsmtFullBath,BsmtHalfBath,FullBath,HalfBath,BedroomAbvGr,\n",
    "KitchenAbvGr,KitchenQual,TotRmsAbvGrd,Functional,Fireplaces,FireplaceQu,GarageType,GarageYrBlt,GarageFinish,\n",
    "GarageCars,GarageArea,GarageQual,GarageCond,PavedDrive,WoodDeckSF,OpenPorchSF,EnclosedPorch,3SsnPorch,ScreenPorch,\n",
    "PoolArea,PoolQC,Fence,MiscFeature,MiscVal,MoSold,YrSold,SaleType,SaleCondition'''\n",
    "\n",
    "f3_tring= '''MSSubClass,LotArea,OverallQual,OverallCond,YearBuilt,YearRemodAdd,1stFlrSF,2ndFlrSF,LowQualFinSF,\\\n",
    "GrLivArea,FullBath,HalfBath,BedroomAbvGr,KitchenAbvGr,TotRmsAbvGrd,Fireplaces,WoodDeckSF,OpenPorchSF,\\\n",
    "EnclosedPorch,3SsnPorch,ScreenPorch,PoolArea,MiscVal,MoSold,YrSold'''\n",
    "\n",
    "#print(f3_tring)\n",
    "\n",
    "features3 = f3_tring.split(',')\n",
    "#print(features3)\n",
    "\n",
    "X3 = home_data[features3]\n",
    "#display(X3.head())\n",
    "\n",
    "# Split into training and validation (test) data\n",
    "train_X3, val_X3, train_y3, val_y3 = train_test_split(X3, y, random_state=1)\n",
    "\n",
    "# Define Random Forest model + fit it with training data + mk val_predicted + calc mae\n",
    "rf_m3 = RandomForestRegressor(random_state=1)\n",
    "rf_m3.fit(train_X3, train_y3)\n",
    "rf_val_pred3 = rf_m3.predict(val_X3)\n",
    "rf_mae3 = mean_absolute_error(val_y3, rf_val_pred3)\n",
    "print(f'rf_mae: {rf_mae3:,.2f}')\n",
    "\n",
    "# r_s=1 --> 17,905.90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state: 777  -->  rf_mae: 16,269.00\n"
     ]
    }
   ],
   "source": [
    "### 3 BIS____\n",
    "def get_mae_randstate(randstate):\n",
    "    train_X3, val_X3, train_y3, val_y3 = train_test_split(X3, y, random_state=randstate)\n",
    "    rf_m3 = RandomForestRegressor(random_state=randstate)\n",
    "    rf_m3.fit(train_X3, train_y3)\n",
    "    rf_val_pred3 = rf_m3.predict(val_X3)\n",
    "    rf_mae3 = mean_absolute_error(val_y3, rf_val_pred3)\n",
    "    return rf_mae3\n",
    "\n",
    "dic = {}\n",
    "for i in range(750, 790):\n",
    "    rf_mae3 = get_mae_randstate(i)\n",
    "    dic[i] = rf_mae3\n",
    "\n",
    "min_mae = min(dic.values())\n",
    "for k in dic.keys():\n",
    "    if dic[k] == min_mae:\n",
    "        k_min = k\n",
    "        break\n",
    "\n",
    "print(f'random_state: {k_min}  -->  rf_mae: {min_mae:,.2f}')\n",
    "\n",
    "# r_s=238 --> 16,829.28\n",
    "# random_state: 450 _1  -->  rf_mae: 16,619.22\n",
    "# random_state: 777 _1  -->  rf_mae: 16,543.76\n",
    "# random_state: 777  -->  rf_mae: 16,269.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'squared_error',\n",
      " 'max_depth': None,\n",
      " 'max_features': 1.0,\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 1,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "### this is JM trying to mk an improved model.\n",
    "## 4. hyperparams?___ \n",
    "    # bootstrap: True (3 examples)\n",
    "    # max_depth: 80 (1 example)\n",
    "    # max_features: 'auto'\n",
    "    # min_samples_leaf: 50 or 5\n",
    "    # min_samples_split: 12\n",
    "    # n_estimators: 100 (2 examples)\n",
    "    # random_state: 777 (above)\n",
    "\n",
    "pprint(rf_m3.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'squared_error',\n",
      " 'max_depth': None,\n",
      " 'max_features': 6,\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 43,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 777,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "rf_mae: 15,769.81\n"
     ]
    }
   ],
   "source": [
    "''' {'bootstrap': True,\n",
    " 'max_depth': 80,\n",
    " 'max_features': 3,\n",
    " 'min_samples_leaf': 5,\n",
    " 'min_samples_split': 12,\n",
    " 'n_estimators': 100} '''\n",
    "\n",
    "''' (n_estimator = 100, oob_score = TRUE, n_jobs = -1,random_state =50,\n",
    "max_features = \"auto\", min_samples_leaf = 50) '''\n",
    "\n",
    "f4_tring= '''MSSubClass,LotArea,OverallQual,OverallCond,YearBuilt,YearRemodAdd,1stFlrSF,2ndFlrSF,LowQualFinSF,\\\n",
    "GrLivArea,FullBath,HalfBath,BedroomAbvGr,KitchenAbvGr,TotRmsAbvGrd,Fireplaces,WoodDeckSF,OpenPorchSF,\\\n",
    "EnclosedPorch,3SsnPorch,ScreenPorch,PoolArea,MiscVal,MoSold,YrSold'''\n",
    "\n",
    "#print(f3_tring)\n",
    "\n",
    "features4 = f4_tring.split(',')\n",
    "#print(features3)\n",
    "\n",
    "X4 = home_data[features4]\n",
    "#display(X3.head())\n",
    "\n",
    "# Split into training and validation (test) data\n",
    "train_X4, val_X4, train_y4, val_y4 = train_test_split(X4, y, random_state=777)\n",
    "\n",
    "# Define Random Forest model + fit it with training data + mk val_predicted + calc mae\n",
    "# rf_m4 = RandomForestRegressor(max_depth=80, max_features=9, min_samples_leaf=5, min_samples_split=12,\n",
    "#                               n_estimators=120, random_state=238)\n",
    "rf_m4 = RandomForestRegressor(n_estimators=43, random_state=777, max_features=6)\n",
    "\n",
    "pprint(rf_m4.get_params())\n",
    "\n",
    "rf_m4.fit(train_X4, train_y4)\n",
    "rf_val_pred4 = rf_m4.predict(val_X4)\n",
    "rf_mae4 = mean_absolute_error(val_y4, rf_val_pred4)\n",
    "print(f'rf_mae: {rf_mae4:,.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_mae5: 19,412.63\n"
     ]
    }
   ],
   "source": [
    "### New rf_model to try other train_test_split parameter specially\n",
    "# from previous: df, and y\n",
    "\n",
    "f5_tring= '''MSSubClass,LotArea,OverallQual,OverallCond,YearBuilt,YearRemodAdd,1stFlrSF,2ndFlrSF,LowQualFinSF,\\\n",
    "GrLivArea,FullBath,HalfBath,BedroomAbvGr,KitchenAbvGr,TotRmsAbvGrd,Fireplaces,WoodDeckSF,OpenPorchSF,\\\n",
    "EnclosedPorch,3SsnPorch,ScreenPorch,PoolArea,MiscVal,MoSold,YrSold'''\n",
    "features5 = f5_tring.split(',')\n",
    "X5 = home_data[features5]\n",
    "train_X5, val_X5, train_y5, val_y5 = train_test_split(X5, y, test_size=.2,\n",
    "                                                      random_state=42)\n",
    "rf_m5 = RandomForestRegressor(random_state=42).fit(train_X5, train_y5)\n",
    "rf_pred5 = rf_m5.predict(val_X5)\n",
    "rf_mae5 = mean_absolute_error(val_y5, rf_pred5)\n",
    "print(f'rf_mae5: {rf_mae5:,.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_mae5: 15,755.64\n"
     ]
    }
   ],
   "source": [
    "### New rf_m6\n",
    "# from previous: df, and y\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "f6_tring= '''MSSubClass,LotArea,OverallQual,OverallCond,YearBuilt,YearRemodAdd,1stFlrSF,2ndFlrSF,LowQualFinSF,\\\n",
    "GrLivArea,FullBath,HalfBath,BedroomAbvGr,KitchenAbvGr,TotRmsAbvGrd,Fireplaces,WoodDeckSF,OpenPorchSF,\\\n",
    "EnclosedPorch,3SsnPorch,ScreenPorch,PoolArea,MiscVal,MoSold,YrSold'''\n",
    "features6 = f6_tring.split(',')\n",
    "X6 = home_data[features6]\n",
    "train_X6, val_X6, train_y6, val_y6 = train_test_split(X6, y, test_size=.2,\n",
    "                                                      random_state=238)\n",
    "\n",
    "# use ensemble Random Forest method to improve accuracy. First we must perform GridSearchCV to find out\n",
    "# the best params.\n",
    "def model_tuning_GS(model, parameter_dict):\n",
    "    \"\"\"Function to perform hyperparameter turning for the classification models\n",
    "    using GridSearch.\"\"\"\n",
    "    # inspect the model params.\n",
    "    model.get_params()\n",
    "    # define the parameters using a dictionary that we want to test.\n",
    "    model_grid = parameter_dict\n",
    "    # initialise a GSCV object with the model as an argument. scoring is set to accuracy and CV set to 5.\n",
    "    Grid_model = GridSearchCV(estimator=model, param_grid=model_grid, cv=10, scoring=\"accuracy\")\n",
    "    # fit the model to data.\n",
    "    Grid_model.fit(train_X6, train_y6)\n",
    "    # extract the best estimator, accuracy score and print them.\n",
    "    print(\"GridSearchCV results:\", model.__class__.__name__)\n",
    "    # print best estimator\n",
    "    print(\"Best Estimator:\\n\", Grid_model.best_estimator_)\n",
    "    # printing the mean cross-validated score of the best_estimator:\n",
    "    print(\"\\n Best Score:\\n\", Grid_model.best_score_)\n",
    "    # printing the parameter setting that gave the best results on the hold out testing data.:\n",
    "    print(\"\\n Best Hyperparameters:\\n\", Grid_model.best_params_)\n",
    "\n",
    "#  call the GridSearchCV function on the random forest.\n",
    "parameter_dict = {'n_estimators': [40, 45, 50, 55, 60],\n",
    "                  'max_depth': [1, 5, 8, 9, 10],\n",
    "                  'min_samples_leaf': [0.1, 0.2],\n",
    "                  #'criterion': ['squared_error', 'friedman_mse', 'poisson', 'absolute_error']}\n",
    "                    'criterion':['gini', 'entropy', 'log_loss']}\n",
    "\n",
    "#model_tuning_GS(RandomForestClassifier(random_state=42), parameter_dict)\n",
    "# --https://towardsdev.com/predicting-the-premier-league-with-random-forest-fbc7d320a37e\n",
    "\n",
    "rf_m6 = RandomForestRegressor(n_estimators=42, random_state=238)\n",
    "rf_m6.fit(train_X6, train_y6)\n",
    "rf_pred6 = rf_m6.predict(val_X6)\n",
    "rf_mae6 = mean_absolute_error(val_y6, rf_pred6)\n",
    "print(f'rf_mae5: {rf_mae6:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model for the competition\n",
    "- The code cell above trains a Random Forest model on train_X and train_y.\n",
    "- Use the code cell below to build a Random Forest model and train it on all of X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To improve accuracy, create a new Random Forest model which you will train on all training data\n",
    "rf_model_on_full_data = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# fit rf_model_on_full_data on all data from the training data\n",
    "rf_model_on_full_data.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to file you will use for predictions\n",
    "''' local '''\n",
    "\n",
    "# read test data file using pandas\n",
    "test_data = pd.read_csv('test.csv')\n",
    "#test_data\n",
    "\n",
    "# create test_X which comes from test_data but includes only the columns you used for prediction.\n",
    "# The list of columns is stored in a variable called features\n",
    "test_X = test_data[features]\n",
    "\n",
    "# make predictions which we will submit. \n",
    "test_preds = rf_model_on_full_data.predict(test_X)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before submitting, run a check to make sure your test_preds have the right format. - ok!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code to save predictions in the format used for competition scoring\n",
    "\n",
    "output = pd.DataFrame({'Id': test_data.Id,\n",
    "                       'SalePrice': test_preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
